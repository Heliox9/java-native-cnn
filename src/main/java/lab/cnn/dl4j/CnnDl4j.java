/*
 * This Java source file was generated by the Gradle 'init' task.
 */
package lab.cnn.dl4j;

import lab.controlBase.commandlineInterface.LoggingBase;
import lab.controlBase.commandlineInterface.questions.*;
import lab.cnn.custom.network.Enums;
import org.datavec.api.io.filters.BalancedPathFilter;
import org.datavec.api.io.labels.ParentPathLabelGenerator;
import org.datavec.api.split.FileSplit;
import org.datavec.api.split.InputSplit;
import org.datavec.image.loader.NativeImageLoader;
import org.datavec.image.recordreader.ImageRecordReader;
import org.deeplearning4j.datasets.datavec.RecordReaderDataSetIterator;
import org.deeplearning4j.eval.Evaluation;
import org.deeplearning4j.nn.multilayer.MultiLayerNetwork;
import org.nd4j.linalg.dataset.api.iterator.DataSetIterator;
import org.nd4j.linalg.dataset.api.preprocessor.DataNormalization;
import org.nd4j.linalg.dataset.api.preprocessor.ImagePreProcessingScaler;

import javax.imageio.ImageIO;
import java.awt.*;
import java.awt.image.BufferedImage;
import java.io.*;
import java.util.Random;

/**
 * Wrapping object to hold end execute a @MultiLayerNetwork from dl4j
 * holds configurations needed for execution
 */
public class CnnDl4j implements Serializable {

    int outputNum; // total output classes
    int height;    // height of the picture in px
    int width;     // width of the picture in px
    int channels;   // single channel for grayscale images
    int batchSize; // number of samples that will be propagated through the network in each iteration
    int nEpochs;    // number of training epochs

    int samplesPerLabel;

    private String name; // used for saving and loading


    /**
     * base constructor
     * sets all needed parameters for the dl4j wrapping
     *
     * @param name      name of the network
     * @param outputNum number of output classes
     * @param height    height of input image
     * @param width     width of input image
     * @param channels  channels for input image
     */
    public CnnDl4j(String name,
                   int outputNum,
                   int height, int width,
                   int channels) {
        this.name = name;
        this.outputNum = outputNum;
        this.height = height;
        this.width = width;
        this.channels = channels;
    }

    /**
     * starts the workflow with a selection of general options and forwards to executions for different modes
     *
     * @param mode    operating mode to execute
     * @param network the network to execute on
     * @return the network after execution
     */
    public MultiLayerNetwork start(Enums.OperatingMode mode, MultiLayerNetwork network) {

        // loop to reuse the same network without restart
        do {
            /* productive mode */
            if (mode == Enums.OperatingMode.PRODUCTIVE) {
                prod(network);
            }
            /* training mode */
            else if (mode == Enums.OperatingMode.TRAINING) {
                network = train(network);
            }
            /* testing mode */
            else if (mode == Enums.OperatingMode.TEST) {
                test(network);
            }
            /* catch unknown modes (redundant check, should be caught by questions) */
            else {
                LoggingBase.log.error("Unknown Mode: " + mode);
            }
            mode = null;

        } while (mode != null);

        // return current network settings for saving
        return network;
    }

    /**
     * initializes the questionaire needed for a training
     *
     * @return mapping:
     * 0: FolderQuestion
     * 1: IntegerQuestion
     * 2: IntegerQuestion
     * 3: IntegerQuestion
     */
    private Object[] trainQuestionaire() {
        Questionaire questionaire = new Questionaire("Training parameters");

        questionaire.addQuestion(new FolderQuestion("Path to train folder: "));
        questionaire.addQuestion(new IntegerQuestion("Number of epochs: "));
        questionaire.addQuestion(new IntegerQuestion("Number of samples per label (high numbers can result in overflowing RAM): "));
        questionaire.addQuestion(new IntegerQuestion("batch size: "));

        return questionaire.ask();
    }

    /**
     * trains a network on the wrapper configuration
     *
     * @param network initialized dl4j network train on
     * @return input network after storing
     */
    private MultiLayerNetwork train(MultiLayerNetwork network) {
        // check if a network is input
        if (network == null) {
            LoggingBase.log.error("Network not configured!");
            return null;
        }

        // configure training
        Object[] answers = trainQuestionaire();

        // set training values
        File trainFolder = (File) answers[0];
        nEpochs = (int) answers[1];
        this.samplesPerLabel = (int) answers[2];
        this.batchSize = (int) answers[3];

        // catch data import exceptions and stop workflow on error
        try {
            // loop through epochs
            for (int i = 0; i < nEpochs; i++) {
                // build data iterators
                // inside loop, so that every epoch trains and tests on a fresh subset
                DataSetIterator[] iters = importData(trainFolder, 80, 20);
                DataSetIterator trainIter = iters[0];
                DataSetIterator testIter = iters[1];

                // fit a dataset for a single epoch
                // fitting trains the network
                network.fit(trainIter);

                // create and log evaluation
                // show stats for the learning progress on the current epoch
                Evaluation eval = network.evaluate(testIter);
                LoggingBase.log.info(eval.stats());
                LoggingBase.log.info("Completed epoch " + (i + 1) + " of " + nEpochs + " (Completion: " + ((double) (i + 1) / (double) nEpochs) * 100 + "%)");

                /*
                 reset iterators for next epoch
                 safety measure
                */
                trainIter.reset();
                testIter.reset();
            }
        } catch (IOException e) {
            LoggingBase.log.error("Could not import data");
            LoggingBase.log.error(e.getMessage());
        }

        // return trained network to save progress
        return network;
    }

    /**
     * initializes the questionaire needed for a testing
     *
     * @return mapping: 0: FolderQuestion
     * 1: IntegerQuestion
     */
    private Object[] testQuestionaire() {
        Questionaire questionaire = new Questionaire("Test parameters");

        questionaire.addQuestion(new FolderQuestion("Path to test folder: "));
        questionaire.addQuestion(new IntegerQuestion("Number of samples per label: "));

        return questionaire.ask();
    }

    /**
     * initializes the questionaire needed for a productive use
     *
     * @return mapping:
     * 0: FileQuestion
     * 1: ChooseQuestion
     */
    private Object[] prodQuestionaire() {
        Questionaire questionaire = new Questionaire("Test parameters");

        questionaire.addQuestion(new FileQuestion("Path to file: "));
        questionaire.addQuestion(new ChooseQuestion("Are multiple characters in image? ", new String[]{"Yes", "No"}));

        return questionaire.ask();

    }


    /**
     * evalute a single image without training
     *
     * @param network initialized dl4j network train on
     * @return input network after storing
     */
    private MultiLayerNetwork prod(MultiLayerNetwork network) {
        // check if a network is input
        if (network == null) {
            LoggingBase.log.error("Network not configured!");
            return null;
        }

        // configure test
        Object[] answers = prodQuestionaire();
        File inputFile = (File) answers[0];

        // check whether a box mapping is needed
        // boxes define single characters with the image
        if (((String) answers[1]).toLowerCase().contains("yes")) {
            // get mapping file for box assignment
            File multiMappingCsv = new FileQuestion("Mapping file: ").ask();

            // reformat image into multiple single digit files
            buildSubimages(inputFile, multiMappingCsv);
        } else {
            // copy to prod folder
            File newLocation = new File("build/prod/prod.png");
            // check if folder exists
            if (newLocation.getParentFile().exists()) {
                // clean all files in folder
                for (String s : newLocation.getParentFile().list()) {
                    new File(newLocation.getParentFile().getAbsolutePath() + "/" + s).delete();
                }
            } else {
                // create directory tree
                newLocation.getParentFile().mkdirs();
            }

            // copy file to temporary folder
            try {
                ImageIO.write(ImageIO.read(inputFile), "png", newLocation);
            } catch (IOException e) {
                e.printStackTrace();
            }

        }

        // create and log evaluation
        try {
            // read images in productive folder
            DataSetIterator iter = importData(new File("build/prod"));

            // build output string
            StringBuilder sBuilder = new StringBuilder();

            // dynamically loop files
            while (iter.hasNext()) {
                // predict value for digit and prediction to output
                for (int s : network.predict(iter.next().getFeatures())) {
                    sBuilder.append(s);
                }
            }

            // log output to console
            LoggingBase.log.info(sBuilder.toString());

        } catch (IOException e) {
            e.printStackTrace();
        }

        // return network to be stored
        return network;
    }

    /**
     * reads image with multiple digits and stores multiple single digit files
     *
     * @param file    image to rebuild
     * @param mapping file to map boxes for
     */
    private void buildSubimages(File file, File mapping) {
        int fileCounter = 0;

        // build parent directory
        File parent = new File("build/prod/");
        if (parent.exists()) {
            for (String s : parent.list()) {
                new File(parent.getAbsolutePath() + "/" + s).delete();
            }
        } else {
            parent.mkdirs();
        }

        // parse csv for box locations
        int[][] boxes = parseBoxCsv(mapping, file.getName());

        // iterate box locations
        for (int[] boxData : boxes) {
            try {
                // read original file
                BufferedImage bufferedImage = ImageIO.read(file);

                // crop original for box bounds
                bufferedImage = crop(bufferedImage, boxData);

                // resize cropped image to fit configured dimensions
                bufferedImage = resize(bufferedImage);

                // write single digit image to file system
                File output = new File("build/prod/" + fileCounter + ".png");
                ImageIO.write(bufferedImage, "png", output);
                fileCounter++;
            } catch (IOException e) {
                e.printStackTrace();
            }
        }

    }

    /**
     * crops image around box bounds.
     * bounds need to contain x and y coorinates for 2 diagonal corners
     *
     * @param original the image to crop
     * @param box      the bounds as defined by the csv file
     * @return the cropped image
     */
    public BufferedImage crop(BufferedImage original, int[] box) {
        // read coordinates from array
        int y1 = box[0];
        int y2 = box[1];
        int x1 = box[2];
        int x2 = box[3];

        // crop image on bounds
        return original.getSubimage(x1, y1, x2 - x1, y2 - y1);
    }


    /**
     * resize image to configured dimensions
     *
     * @param original loaded image in any dimensions
     * @return refactored image
     */
    public BufferedImage resize(BufferedImage original) {
        // creates output image (as empty buffer space)
        BufferedImage outputImage = new BufferedImage(width,
                height, original.getType());

        // scales the input image to the output image
        Graphics2D g2d = outputImage.createGraphics();
        g2d.drawImage(original, 0, 0, width, height, null);

        // clear unneeded graphic buffer
        g2d.dispose();

        return outputImage;
    }

    /**
     * parses csv mapping for boxes
     *
     * @param boxCsv    mapping file
     * @param imageName name to parse the list for
     * @return int[boxes][values]
     */
    public int[][] parseBoxCsv(File boxCsv, String imageName) {
        // init array to store boxes to
        int[][] boxes;

        BufferedReader csvReader = null;

        // check if file matches pattern
        if (boxCsv.exists() && boxCsv.getAbsolutePath().endsWith(".csv")) {
            String row;
            try {
                // setup reader on file
                csvReader = new BufferedReader(new FileReader(boxCsv));

                // parse line by line
                while ((row = csvReader.readLine()) != null) {

                    // split line by column
                    String[] data = row.split(";");

                    // check if first column matches name
                    if (data[0].equals(imageName)) {
                        boxes = new int[data.length - 1][5];

                        // interate other columns
                        for (int i = 1; i < data.length; i++) {
                            // split column for parameters
                            String[] boxData = data[i].split(",");

                            // interate parameters
                            for (int j = 0; j < 5; j++) {
                                boxes[i - 1][j] = Integer.parseInt(boxData[j]);
                            }
                        }

                        // close reader to prevent file locking
                        csvReader.close();
                        return boxes;
                    }
                }
            } catch (IOException e) {
                LoggingBase.log.error("Unexpected file read error", e);
            } finally {
                // close reader to prevent file locking
                try {
                    csvReader.close();
                } catch (IOException e) {
                    LoggingBase.log.error("Could not close file reader", e);
                }
            }
        } else {
            LoggingBase.log.error("Can't read file at " + boxCsv.getAbsolutePath());
            return null;
        }
        LoggingBase.log.error("Filename: " + imageName + " not included in: " + boxCsv.getAbsolutePath());
        return null;
    }


    /**
     * evalute multiple images without training
     *
     * @param network configured and initialized network
     * @return network after testing
     */
    private MultiLayerNetwork test(MultiLayerNetwork network) {
        // check network to existance
        if (network == null) {
            LoggingBase.log.error("Network not configured!");
            return null;
        }

        // configure test
        Object[] answers = testQuestionaire();

        // set training values
        File testFolder = (File) answers[0];
        nEpochs = 1;
        this.samplesPerLabel = (int) answers[1];
        this.batchSize = 1;

        try {
            // build data iterators (full data on testing)
            DataSetIterator[] iters = importData(testFolder, 0, 100);
            DataSetIterator testIter = iters[1];
            iters = null;

            // create and log test output
            Evaluation eval = network.evaluate(testIter);
            LoggingBase.log.info(eval.stats());

            // reset iterator
            testIter.reset();
        } catch (IOException e) {
            LoggingBase.log.error("Could not import data");
            LoggingBase.log.error(e.getMessage());
        }

        return network;
    }

    /**
     * read all image files in dir for processing in network
     *
     * @param parentDir the directory to read
     * @return iterator over the given folder
     * @throws IOException when files can't be loaded
     */
    private DataSetIterator importData(File parentDir) throws IOException {
        // initilize iterator
        DataSetIterator iter = null;
        FileSplit filesInDir = new FileSplit(parentDir, NativeImageLoader.ALLOWED_FORMATS);

        // reader setup
        ImageRecordReader recordReader = new ImageRecordReader(width, height, channels, new ParentPathLabelGenerator());
        DataNormalization imageScaler = new ImagePreProcessingScaler();

        // read files
        recordReader.initialize(filesInDir);

        // setup train interator
        iter = new RecordReaderDataSetIterator(recordReader, 1, 1, outputNum);

        // pixel values from 0-255 to 0-1 (min-max scaling)
        imageScaler.fit(iter);
        iter.setPreProcessor(imageScaler);

        return iter;
    }


    /**
     * read defined number of images in folder and splits into test and train set
     *
     * @param parentDir       the directory to read
     * @param trainPercentage percentage of files for training
     * @param testPercentage  percentage of files for testing
     * @return iterators for the split datasets:
     * 0: training
     * 1: testing
     * @throws IOException when files can't be loaded
     */
    private DataSetIterator[] importData(File parentDir, int trainPercentage, int testPercentage) throws IOException {
        DataSetIterator trainIter = null;
        DataSetIterator testIter = null;

        // normailze total percentage to 100
        int totalPercentage = trainPercentage + testPercentage;
        int temp = 0;
        if (totalPercentage != 100) {
            // recalculate train percentage
            temp = trainPercentage / totalPercentage;
            trainPercentage = temp * trainPercentage;

            // recalculate test percentage
            temp = testPercentage / totalPercentage;
            trainPercentage = temp * testPercentage;
        }

        //read and label data
        //  File parentDir = new File(dataPath);
        FileSplit filesInDir = new FileSplit(parentDir, NativeImageLoader.ALLOWED_FORMATS);
        ParentPathLabelGenerator labelMaker = new ParentPathLabelGenerator();

        // split data for train and test
        BalancedPathFilter pathFilter = new BalancedPathFilter(new Random(), labelMaker, samplesPerLabel);
        InputSplit[] filesInDirSplit = filesInDir.sample(pathFilter, trainPercentage, testPercentage);


        // reader setup
        ImageRecordReader recordReader = new ImageRecordReader(width, height, channels, labelMaker);
        DataNormalization imageScaler = new ImagePreProcessingScaler();

        // build training dataset
        if (trainPercentage > 0) {
            // read training data
            InputSplit trainData = filesInDirSplit[0];
            recordReader.initialize(trainData);

            // setup train interator
            trainIter = new RecordReaderDataSetIterator(recordReader, batchSize, 1, outputNum);

            // pixel values from 0-255 to 0-1 (min-max scaling)
            imageScaler.fit(trainIter);
            trainIter.setPreProcessor(imageScaler);

        }

        // build testing dataset
        if (testPercentage > 0) {
            // setup test interator
            InputSplit testData = filesInDirSplit[1];

            // vectorization of test data
            ImageRecordReader testRR = new ImageRecordReader(height, width, channels, labelMaker);
            testRR.initialize(testData);

            // build record reader
            testIter = new RecordReaderDataSetIterator(testRR, batchSize, 1, outputNum);

            // normalize with same loader as testing
            testIter.setPreProcessor(imageScaler); // same normalization for better results
        }

        // build and return array (can contain null values)
        return new DataSetIterator[]{
                trainIter,
                testIter
        };

    }

    public String getName() {
        return name;
    }
}
